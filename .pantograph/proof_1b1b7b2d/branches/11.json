{
  "initial_expr": "\u2200 (input : List Int) (i : Nat) (hi : i < input.length) (p : Nat) (hp : p = (pileAssignment input)[i]!) (hp_lt : p < (stateAtStep input i).piles.size), (stateAtStep input (i + 1)).piles[p]! = input[i]!",
  "initial_sketch": null,
  "initial_imports": [
    "ArtificialAlgorithms.DynamicProgramming.VerifiedLIS"
  ],
  "proof_steps": [
    {
      "step_type": "tactic",
      "tactic": "intro input i hi p hp hp_lt",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    },
    {
      "step_type": "tactic",
      "tactic": "unfold stateAtStep",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    },
    {
      "step_type": "tactic",
      "tactic": "have h_state_i : (stateAfter input (initLISState input) i).processed = i := by rw [stateAfter_processed]; simp [initLISState]; omega",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    },
    {
      "step_type": "tactic",
      "tactic": "have h_proc_lt : (stateAfter input (initLISState input) i).processed < input.length := by rw [h_state_i]; exact hi",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    },
    {
      "step_type": "tactic",
      "tactic": "conv_lhs => rw [show i + 1 = i + 1 from rfl]; unfold stateAfter; simp only [Nat.add_one_ne_zero, \u2193reduceIte]",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    },
    {
      "step_type": "tactic",
      "tactic": "have h_init_lt : (initLISState input).processed < input.length := by simp [initLISState]; omega",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    },
    {
      "step_type": "tactic",
      "tactic": "intro input i hi p hp hp_lt",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    },
    {
      "step_type": "tactic",
      "tactic": "have h_proc : (stateAtStep input i).processed = i := by rw [stateAtStep_processed]; simp; omega",
      "goal_id": null,
      "focused_goal_id": null,
      "focused_goal_index": null
    }
  ],
  "tactic_history": [
    "intro input i hi p hp hp_lt",
    "unfold stateAtStep",
    "have h_state_i : (stateAfter input (initLISState input) i).processed = i := by rw [stateAfter_processed]; simp [initLISState]; omega",
    "have h_proc_lt : (stateAfter input (initLISState input) i).processed < input.length := by rw [h_state_i]; exact hi",
    "conv_lhs => rw [show i + 1 = i + 1 from rfl]; unfold stateAfter; simp only [Nat.add_one_ne_zero, \u2193reduceIte]",
    "have h_init_lt : (initLISState input).processed < input.length := by simp [initLISState]; omega",
    "intro input i hi p hp hp_lt",
    "have h_proc : (stateAtStep input i).processed = i := by rw [stateAtStep_processed]; simp; omega"
  ],
  "goals": [
    {
      "id": "_uniq.231",
      "target": "\u2200 (input : List Int) (i : Nat) (hi : i < input.length) (p : Nat) (hp : p = (pileAssignment input)[i]!) (hp_lt : p < (stateAtStep input i).piles.size), (stateAtStep input (i + 1)).piles[p]! = input[i]!",
      "variables": [],
      "sibling_dep": null
    }
  ],
  "is_solved": false,
  "current_goal_index": null,
  "search_tree_id": "proof_1b1b7b2d",
  "branch_id": "11"
}